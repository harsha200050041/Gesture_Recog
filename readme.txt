This is a mini project on gesture_recognition based on pre trained Models from Mediapipe
Reason for choosing this is , It was hard to build a recognition pipeline and train the neural network
from scratch in the given 24 hrs.
So to improvise or compensate for that I have made live feed detection along with marking the key landmarks so that we could Identify the
21 landmarks based on which the detection is performed.
Mediapipe has predefined functionalities which helps us to write the Gesture Recognition code in a simple and efficent way
Took help of the official mediapipe documentation which was available on google
->https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer

Pre Defined Classes for Gesture Recognition : 
Open Palm,
Close Palm,
Pointing Up,
Victory,
Thumbs Up,
Thumbs Down,
Ilubyou,
None.

The model classifies your action into one of the following  based on a confidence score.

